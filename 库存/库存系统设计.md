# 库存系统设计

## 1 秒杀场景

参考资料：https://time.geekbang.org/column/article/427445

对于库存系统来说，如果我只卖 100 件商品，那理想状态下，我希望外部系统就放过来 100 个下单请求就好了（以每单购买 1 件来说），因为再多的请求过来，库存不足，也会返回失败。并且对于像秒杀这种大流量、高并发的业务场景，更不适合直接将全部流量打到库存系统，所以这个时候就需要有个系统能够承接大流量，并且只放和商品库存相匹配的请求量到库存系统，而限购就承担这样的角色。限购之于库存，就像秒杀之于下单，前者都是后者的过滤网和保护伞。

库存系统：不关注你要买什么，而是我自己有什么

限购系统：目的是过滤出有效请求，既要关注你要买什么，也要关注库存有什么。限购系统必须要能扛住高并发

### 1.1 限购的玩法（业务功能）

- 商品维度的限制

  - 活动库存
  - 位置（仓库）库存：商品只在固定的几个城市投放，并且各城市的库存是相互隔离的

- 个人维度的限制

  - 用户ID、手机号、收货地址、设备IP 等
  - 主要是为了秒杀的公平性，使得优惠可以覆盖更多人

  

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220116123412212.png" alt="image-20220116123412212" style="zoom:50%;" />

### 1.2 活动库存扣减的问题

限购虽然可以为库存服务扛住高并发原始流量，并过滤掉大量无效请求（如已经卖完的商品），但仍然会有很多的请求打到库存服务，尝试去进行库存的扣减。

在需要严格禁止出现超卖的原则下，库存扣减并非一步操作，而是需要分为两步：

1. 查询商品库存
2. 库存充足的情况下，做数量的扣减

因为这两步不具备原子性和顺序性，因此在高并发场景下，是有可能造成库存超卖的。

> 假如A线程和B线程都收到扣减库存的请求，对应的查询和扣减操作分别记为 A1、A2，B1、B2。这里的原子性和顺序性可以如下理解：
>
> 原子性：A1、A2 和 B1、B2 分别同时成功或同时失败。即使具备原子性，在高并发下，仍然可能会出现[A1,A2] [B1、B2]同时成功造成超卖的情况
>
> 顺序性：如果先接收到A请求，那么 A1在 B1之前，A2 的执行在 B2 执行之前（假如线程执行的代码的速度恒定），也可能会超卖

造成超卖的场景如下图：

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220116124010670.png" alt="image-20220116124010670" style="zoom:50%;" />

要解决这个问题，关键是要保证「库存扣减」的原子性，将以上场景限制为：

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220116124122092.png" alt="image-20220116124122092" style="zoom:50%;" />

### 1.3 解决方案

```sql
CREATE TABLE `t_stock` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `resource_id` varchar(128) NOT NULL COMMENT '库存所属资源id',
  `resource_type` tinyint unsigned NOT NULL COMMENT '库存所属资源类型',
  `origin_count` int unsigned NOT NULL DEFAULT '0' COMMENT '原始库存总数',
  `sum_count` int unsigned NOT NULL COMMENT '库存总数',
  `total_count` int unsigned NOT NULL COMMENT '可用库存总数',
  `withholding_count` int unsigned NOT NULL COMMENT '预扣库存总数',
  `warehouse_id` varchar(64) NOT NULL DEFAULT '' COMMENT '仓库ID',
  `start_time` int NOT NULL DEFAULT '0' COMMENT '日历库存时间段起点',
  `end_time` int NOT NULL DEFAULT '0' COMMENT '日历库存时间段终点',
  `status` tinyint unsigned NOT NULL COMMENT '库存状态',
  `logid` varchar(128) NOT NULL DEFAULT '' COMMENT '最后变更库存请求的logid',
  `delete_at` int NOT NULL DEFAULT '0' COMMENT '删除时间戳，不删除时为0',
  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '更新时间',
  `extra` varchar(1024) NOT NULL DEFAULT '' COMMENT '冗余json字符串，业务自行存储',
  `stock_id` bigint unsigned NOT NULL COMMENT '发号器生成唯一主键',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uniq_stock_id` (`stock_id`),
  UNIQUE KEY `uniq_resource_warehouse_time_delete` (`resource_id`,`resource_type`,`warehouse_id`,`start_time`,`delete_at`)
) ENGINE=InnoDB AUTO_INCREMENT=15993 DEFAULT CHARSET=utf8mb3 COMMENT='库存表格'

CREATE TABLE `t_stock_flow` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `stock_id` bigint unsigned NOT NULL COMMENT '流水所属库存ID',
  `source_order_no` varchar(128) NOT NULL COMMENT '流水关联的业务单据编号',
  `quantity` int NOT NULL COMMENT '库存变更数量',
  `from_sum_count` int unsigned NOT NULL DEFAULT '0' COMMENT '变更前总库存',
  `to_sum_count` int unsigned NOT NULL DEFAULT '0' COMMENT '变更后总库存',
  `from_total_count` int unsigned NOT NULL DEFAULT '0' COMMENT '结算前可用库存',
  `to_total_count` int unsigned NOT NULL DEFAULT '0' COMMENT '结算后可用库存',
  `from_withholding_count` int unsigned NOT NULL DEFAULT '0' COMMENT '变更前预扣库存',
  `to_withholding_count` int unsigned NOT NULL DEFAULT '0' COMMENT '变更后预扣库存',
  `operation` tinyint unsigned NOT NULL DEFAULT '0' COMMENT '流水变更事件类型',
  `operator` varchar(128) NOT NULL DEFAULT '' COMMENT '操作员',
  `source_psm` varchar(128) NOT NULL DEFAULT '' COMMENT '调用库存的psm',
  `source_type` tinyint NOT NULL DEFAULT '0' COMMENT '标记库存变更来源类型：0-默认; 1-订单；2-商户；3-运营',
  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `logid` varchar(128) NOT NULL DEFAULT '' COMMENT '写入当前流水的业务logid',
  `extra` varchar(1024) NOT NULL DEFAULT '' COMMENT '冗余json字符串，业务自行存储',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uniq_stock_id_source_order_no_operation` (`stock_id`,`source_order_no`,`operation`)
) ENGINE=InnoDB AUTO_INCREMENT=168528 DEFAULT CHARSET=utf8mb3 COMMENT='库存流水表'
```



#### 方案1：数据库行锁

```sql
db.transaction.on
--- 1. select for update 为库存行记录加锁，只有在事务中才会生效
select id, stock_id, resource_id,total_count, sum_count, withholding_count, origin_count
for update
from t_stock
--- 2. 利用 1 和 请求中待扣减的库存数量 num 组装库存流水

--- 3. 批量插入库存流水（for循环，实际上是多个sql）

--- 4. 批量更新库存记录（for循环）

```

**优点：**简单安全

**缺点**：性能比较差，能够承受的 qps 上限是 400（这里的 qps 指的是接口级别的 qps）

#### 方案2：分布式锁

1. 通过 redis 或者 zk 实现一个分布式锁，以 sku 的 sku_id 的维度加锁。
2. 库存扣减请求过来时，先获取分布式锁，获取成功才继续请求库存服务，进行库存的扣减

这种方案避免使用数据库的行锁，造成性能下降。数据库在无锁情况下能承受的 qps 可以参考以下数据计算：

>4核8G -- TPS:1200+，QPS:3600+ （腾讯云的cdb 实例，低配）
>
>4核16G -- TPS:3000+，QPS:9000+ （腾讯云的cdb 实例，中低配）
>
>8核32G -- TPS:5000+，QPS:12500+ （腾讯云的cdb 实例，中高配）
>
>16核64G -- TPS:7000+，QPS:20000+（腾讯云的cdb 实例，高配）

注意：数据库是对象时，tps 指的是数据库每秒执行的事务数，qps 指的是每秒处理的请求（读请求+写请求）数。一般可以按一个事务中执行3个请求计算对应的 qps。而方案一中的 qps 400 指的是接口级别的 qps，一般一个接口的执行时间 = 数据库处理时间+逻辑处理时间

不过单单从以上数据，简单转换成接口 qps 的话，使用分布式锁方案，也可以使得 qps 达到5000甚至更多，不过单台机器想要再往上突破，就比较困难了。这个时候可以通过横向扩展，比如分库分表来将商品分散，从而提高系统整体的 qps。

**缺点：**

分布式锁的使用有很多坑：

1. 分布式锁的过期时间设置是一个难题：

   - 首先一定要设置自动过期时间。不能完全依赖业务代码的主动释放。因为一旦业务代码出错，甚至极端情况下出现机器宕机，而此时又存在未被释放的分布式锁，那么这部分锁系统就永远没办法释放，变成死锁。到时候只能通过人工介入，人工删除的方式释放

   - 自动过期时间设置过短。可能上一个获取到锁的线程还未执行完当前这个扣减库存的流程，锁就释放了。并且立刻被下一个线程获取，这样就相当于锁失效，会出现开头说的超卖问题

   - 自动过期时间设置过长。业务代码中会在业务处理完成的最后一步进行分布式锁的释放，但是一旦这一步出现异常，会导致所有的业务线程都会阻塞等到直到锁自动失效，这就不符合秒杀场景了。
   - 一般只能根据经验去配置过期时间：接口的平均耗时+一点buffer

2. 分布式锁需要对线程做区分

   - 线程A获取的锁必须只能有线程A去释放。否则可能出现这样的场景：A获取到锁，A遇到异常情况（比如内部RPC调用超时）执行时间过长，锁超时被释放；B获取到锁，此时A将锁释放，但释放的其实是 B 获取到的锁。



对于过期时间的问题就没有解决方案了吗，有：锁自动续期，详情可查看：https://z.itpub.net/article/detail/BEE8B16481D16C3E2B2565461ACA66D5。简单总结如下：

启动一个守护线程，业务线程获取锁成功之后，会将持有锁的线程保存下来，然后每隔 10 秒检查一下，如果客户端还持有锁，就延长锁的时间。判断方式：判断当前持有锁的客户端是否是之前保存下来的客户端线程。

综上，通过分布式锁的方式可以实现 qps 的提高，但并不建议使用

#### 方案3：在 redis 中直接完成扣减

redis 是单线程的，也就是说，发送给 redis 的所有请求，最后执行都是由一个线程完成。所以 redis 天然解决了顺序性的问题。因此我们关键是保证查询和扣减具备原子性。

redis 支持执行 Lua 脚本，可以在 Lua 脚本中，调用 redis 的原生 API，完成查询和扣减两步动作。

> Redis 执行 Lua 脚本会将 Lua 脚本当做是一个命令去执行，这是我们认为的原子性。但实际上，原子性还包括在发生异常时，程序自动回滚，这个 redis 并不会帮我们做。需要我们在 Lua 脚本中考虑到这种情况。
>
> 不过在当前库存扣减场景，Redis 的命令就两种，一个读一个写，并且写命令在最后，写成功就成功了，写失败就失败了，并不需要回滚之前的操作（因为之前只是一个查询，没有写操作）。

那接下来的问题就是如何具体编码了，主要是：

- 该如何写 Lua 脚本
- redis又怎么执行呢？

参考 https://blog.csdn.net/qq_41768400/article/details/106630059 写一份 golang 版本的 lua 调用 redis 的逻辑。同时实现了限购+秒杀的功能：

> Lua 语法：local 表示声明局部变量

```go
package main

import (
	"fmt"
	"github.com/go-redis/redis"
	"log"
	"sync"
)


func createScript() *redis.Script {
	script := redis.NewScript(`
		local goodsSurplus
		local flag
		local existUserIds    = tostring(KEYS[1])
		local memberUid       = tonumber(ARGV[1])
		local goodsSurplusKey = tostring(KEYS[2])
		local hasBuy = redis.call("sIsMember", existUserIds, memberUid)

		if hasBuy ~= 0 then
		  return 0
		end
		

		goodsSurplus =  redis.call("GET", goodsSurplusKey)
		if goodsSurplus == false then
		  return 0
		end
		
		-- 没有剩余可抢购物品
		goodsSurplus = tonumber(goodsSurplus)
		if goodsSurplus <= 0 then
		  return 0
		end
		
		flag = redis.call("SADD", existUserIds, memberUid)
		flag = redis.call("DECR", goodsSurplusKey)
		
		return 1
	`)
	return script
}


func evalScript(client *redis.Client, userId string, wg *sync.WaitGroup){
	defer wg.Done()
	script := createScript()
	sha, err := script.Load(client.Context(), client).Result()
	if err != nil {
		log.Fatalln(err)
	}
	ret := client.EvalSha(client.Context(), sha, []string{  // EvalSha 执行预加载好的 lua 脚本，这种方式可以避免同样一个脚本每次执行时都需要重新加载
		"hadBuyUids",
		"goodsSurplus",
	}, userId)
	if result, err := ret.Result();err!= nil {
		log.Fatalf("Execute Redis fail: %v", err.Error())
	}else {
		fmt.Println("")
		fmt.Printf("userid: %s, result: %d", userId, result)
	}
}

func main() {
	var wg sync.WaitGroup
	client := redis.NewClient(&redis.Options{
		Addr:     "localhost:6379",
		Password: "", // no password set
		DB:       0,  // use default DB
	})
	for _, v := range []string{"5824742984", "5824742984", "5824742983", "5824742983", "5824742982", "5824742980"}{
		wg.Add(1)
		go evalScript(client, v, &wg)
	}
	wg.Wait()

}
```

## 2 减库存的核心逻辑

参考文档：https://time.geekbang.org/column/article/40743

减库存的几种方式：

- 下单减库存：最简单，但可能出现下单不付款的情况，被竞争对手利用
- 付款减库存：会出现用户下单成功但付款失败的情况，因为付款时库存不足
- 预扣库存：下单时预占库存，未在规定时间内付款则释放库存，在规定时间内付款则正式扣减库存。相对复杂一些

大型秒杀中如何选择呢？

一般业务场景下会选择预扣库存的方案，而秒杀中采用”下单减库存“更合理，理由：

1. 排除恶意刷单的情况，秒杀场景下下单成功但不付款的情况比较少
2. 下单减库存逻辑最简单、链路最短，性能上更占优势

下单减库存的具体实现：

扣减库存：

```go
// DecrStockByID 
func (s *TStock) DecrStockByID(ctx context.Context, tx *gorm.DB, stockID int64, dbIDStockDecr *StockCountDeltaInfo) error {
	if tx == nil {
		tx = mysql.DB
	}

	logID := ctxvalues.LogIDDefault(ctx)

	updateMap := map[string]interface{}{
		"origin_count": gorm.Expr("origin_count - ?", dbIDStockDecr.Quantity),
		"sum_count":    gorm.Expr("sum_count - ?", dbIDStockDecr.Quantity),
		"total_count":  gorm.Expr("total_count - ?", dbIDStockDecr.Quantity),
		"logid":        logID,
	}

	ret := tx.WithContext(ctx).
		Clauses(clause.Returning{
			Columns: []clause.Column{{Name: "sum_count"}, {Name: "total_count"}},
		}).
		Model(&s).
		Where("stock_id = ? and total_count >=? and status = ?", stockID, dbIDStockDecr.Quantity, common.StockStatus_Online).
		Updates(updateMap)
	if ret.Error != nil {
		return errors.Wrap(ret.Error, "db execute error")
	}

	if ret.RowsAffected == 0 {
		return errors.Wrap(mysql.NewOutOfRangeError("affected rows is zero,probably out of stock"), "")
	}

	return nil
}
```

事务中扣减库存+记录流水

```sql
err = mysql.DB.Transaction(func(tx *gorm.DB) error {
		for id, v := range dbIDStockCountMap {
			stockItem := &dao.TStock{
				ID:      id,
				StockID: v.StockID,
			}
			if err = stockItem.DecrStockByID(ctx, tx, v); err != nil {
				return err
			}
			
			toTStocks = append(toTStocks, stockItem)

			if stockItem.SumCount < stockItem.WithholdingCount {
				return aberr.SKU_STOCK_SHORTAGE.WithMessage("totalStock must gt withholding_count")
			}

			tStockFlow := converter.GenerateStockFlowByReturning(ctx, stockItem, v, opInfo)
			// 写入流水
			if ret := tx.WithContext(ctx).Create(&tStockFlow); ret.Error != nil {
				return ret.Error
			}
		}

		return nil
	})
	
	// 生成stockCount
	stockCountList = generateRespStock(toTStocks, dbIDStockCountMap, err)
```

### 2.1 超卖问题

库存中超卖是不能越过的底线。无论是在秒杀场景还是日常下单场景，都需要避免超卖。具体来说有两点：

1. 卖出去的库存与数据库中减掉的库存数量是一致的
2. 在 1 的前提下，保证库存不能减为负数。

具体有以下几种做法：

#### 1 sql 中判断库存不能为负数

```sql
update t_stock set total_count = total_count - ? 
where stock_id = ? and total_count-?>0
```

#### 2 sql 中使用 case when

```sql
UPDATE item SET inventory = CASE WHEN inventory >= xxx THEN inventory-xxx ELSE inventory END
```

#### 3 使用无符号数

即设置 `total_count` 为 `unsigned int`

这样一旦数字减为负数时，数据库会抛出 `outOfRange` 的异常并回滚

我们的库存系统中，选择了第三种方案

### 2.2 秒杀场景的大并发写

秒杀场景下并发量会非常大，如果库存足够，比如某爆款有 1w 库存。那么有可能在 1s 内会有 1w 的写 qps，并且是单行的写 qps。使用公司内的 mysql 做压测，发现单行热点更新的 qps 上限大概是 700 qps。这与 1w 相差甚远，是没法在秒杀场景中扛住那么多流量的。

那么怎么解决呢？有几种解决方案：

#### 方案一：分片

拆分热点 key 到不同数据库中。假如单行热点更新的 qps 上限是 700，业务要求是 1w。那么可以采用堆机器的方式，加 20 个数据库，这样的话 700*20 = 1.4w 的qps。然后在应用层对请求做分发即可。

但显然这样的方式对于数据的维护比较困难（比如要人工拆分数据，将数据录入到数据库，活动结束后还要计算各个数据库中的剩余库存）。同时也是非常消耗机器资源的。

#### 方案二：流量削峰

- 应用层做排队（业务代码中实现）。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。

- 数据库层做排队。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。

其实对于这种瓶颈在数据库层面的问题，可以多关注下公司内专门的数据库团队是否有这方面的优化。像阿里团队就有很多这方面的探索：

如 COMMIT_ON_SUCCESS 和 ROLLBACK_ON_FAIL 的补丁程序，配合在 SQL 里面加提示（hint），在事务里不需要等待应用层提交（COMMIT），而在数据执行完最后一条 SQL 后，直接根据 TARGET_AFFECT_ROW 的结果进行提交或回滚，可以减少网络等待时间（平均约 0.7ms）

## 3 高并发场景下的库存模型

### 3.1 搜索高并发优化

#### 优化思路：

- 减少请求到数据库的无效请求

  - 产品目录化。从产品层、业务层解决问题。比如用户现在需要购买一张 2022-01-23 从北京到上海的机票。过往的交互方式是上游接到请求，就会把请求下放到库存系统去做，由库存系统去查询库表，完成数据的组装再返回给上游。产品目录化的意思，相当于库存提前把自己存储的信息告诉上游。上游收到请求之后，自己做搜索、组合

  - 缓存闭环协议。
    - 与上游沟通，看看对方是否有缓存，有的话是否可以开放出来，也就是说，我们系统在对方系统的缓存闭环协议下主动更新它的缓存
    - 开放自己的缓存，让上游可以直接通过我们的缓存取数据，当然前提也是遵守我们的缓存协议（读开放，写不开放）这一点和上面的产品目录化是结合在一起做的

- 提高缓存命中率
  - 请求重放。将搜索请求定时录入到队列中，通过队列实现定时的重放请求
    - 对于冷门搜索的航线，请求的时间间隔可能是几个小时，但缓存的过期时间可能只有分钟级。这就意味着每一个冷门行业的搜索都会直接打到库存系统，相当于数据库性能会被很小的一部分数据影响到。通过请求重放的方式，使得即使是冷门搜索的航线也能具备一定的热度 
  - 提升更新效率。基于请求重放，根据不同的业务场景，准备不同频率的更新任务。抽象出 cache manager 这层，对库存数据库的任何变化做响应，进一步去更新缓存

- 数据库中不存在的商品或已经无货的商品，无需再请求数据库

####  全流程异步

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220123233501224.png" alt="image-20220123233501224" style="zoom:50%;" />

- 命中缓存直接返回
- 未命中缓存时，调用方将请求放入回调队列中，同时缓存系统去实时搜索，搜索完毕后回调消息

### 3.2 库存交易的高并发优化

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220123233839655.png" alt="image-20220123233839655" style="zoom:50%;" />

引入大数据领域的架构：

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220123233911633.png" alt="image-20220123233911633" style="zoom:50%;" />

### 3.3 常用套路

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220123234426886.png" alt="image-20220123234426886" style="zoom:50%;" />

### 3.4 总结

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220123234521780.png" alt="image-20220123234521780" style="zoom:50%;" />



缓存方案的设计：

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20220123234552574.png" alt="image-20220123234552574" style="zoom:50%;" />
